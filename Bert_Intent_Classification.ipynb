{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e817e1e6",
   "metadata": {},
   "source": [
    "<h1>BERT(Bidirectional Encoder Representations from Transformers)</h1><br>\n",
    "\n",
    "<p style=\"font-size: 16px;\">It is a transformer-based machine learning technique for natural language processing pre-training developed by Google. BERT was created and published in 2018 by Jacob Devlin and his colleagues from Google.</p>\n",
    "\n",
    "<p style=\"font-size: 16px;\">BERT uses bidirectional training i.e it reads the sentence from both directions to understand the context of the sentence.</p>\n",
    "\n",
    "<p style=\"font-size: 16px;\">Note that BERT is just an encoder. It does not have a decoder.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcd35d7",
   "metadata": {},
   "source": [
    "<h1>Transformer</h1>\n",
    "<br>\n",
    "<p style=\"font-size: 16px;\">\n",
    "Google introduced the transformer architecture in the paper “Attention is All you need”. The transformer uses a self-attention mechanism, which is suitable for language understanding.</p>\n",
    "<p style=\"font-size: 16px;\">\n",
    "Let’s say “I went to the Himalayas this summer. I really enjoyed my time out there”. The last word “there” refers to the Himalayas. But to understand this, remembering the first few parts is essential. To achieve this, the attention mechanism decides at each step of an input sequence which other parts of the sequence are important.</p>\n",
    "<p style=\"font-size: 16px;\">\n",
    "The transformer has an encoder-decoder architecture. They are composed of modules that contain feed-forward and attention layers.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b3f3c4",
   "metadata": {},
   "source": [
    "<h1>Pytorch:</h1><br>\n",
    "<p style=\"font-size: 16px;\">\n",
    "PyTorch is a Python-based scientific computing package that uses the power of graphics processing units(GPU). Since its release in January 2016, many researchers have continued to increasingly adopt PyTorch. It has quickly become a go-to library because of its ease in building extremely complex neural networks. It is giving a tough competition to TensorFlow especially when used for research work.\n",
    "\n",
    "Some of the key highlights of PyTorch includes:\n",
    "\n",
    "Simple Interface: It offers easy to use API.\n",
    "\n",
    "Pythonic in nature: This library, being Pythonic, smoothly integrates with the Python data science stack.\n",
    "\n",
    "Tensors: It is basically the same as a NumPy array. To run operations on the GPU, just cast the Tensor to a Cuda datatype.\n",
    "\n",
    "Computational graphs: PyTorch provides an excellent platform that offers dynamic computational graphs.\n",
    "\n",
    "AUTOGRAD(Automatic Differentiation): This class is an engine to calculate derivatives.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5507a4",
   "metadata": {},
   "source": [
    "<h1>Import Libraries</h1>\n",
    "<p style=\"font-size: 16px;\">Importing the libraries that are required to perform operations on the dataset.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d03fb56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt# specify GPU\n",
    "device = torch.device('mps')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91159c80",
   "metadata": {},
   "source": [
    "<h1>Load Dataset</h1>\n",
    "We load the training dataset here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0711cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want a flat white , please .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I want a salted caramel hot chocolate .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Have a great day !</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hey there !</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Could I get a black tea , please ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text  label\n",
       "0           I want a flat white , please .      1\n",
       "1  I want a salted caramel hot chocolate .      1\n",
       "2                       Have a great day !      4\n",
       "3                              Hey there !      3\n",
       "4       Could I get a black tea , please ?      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./data/processed/train.csv')\n",
    "test_df = pd.read_csv('./data/processed/test.csv')\n",
    "\n",
    "train_df = train_df.loc[:, ~train_df.columns.str.contains('^Unnamed')]\n",
    "test_df = test_df.loc[:, ~test_df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1d27f0",
   "metadata": {},
   "source": [
    "<h4>To convert these categorical labels into numerical encodings we are using the LabelEncoder.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49c22a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.25\n",
       "3    0.25\n",
       "2    0.25\n",
       "1    0.25\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the labels into encodings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train_df['label'] = le.fit_transform(train_df['label'])# check class distribution\n",
    "\n",
    "# check class distribution\n",
    "train_df['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4b6a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing data\n",
    "train_text, train_labels = train_df['text'], train_df['label']\n",
    "test_text, test_labels = test_df['text'], test_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca39032",
   "metadata": {},
   "source": [
    "<h1>BERT Model</h1>\n",
    "Importing the Bert model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3977d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, BertTokenizerFast# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')# Import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24f0a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = []\n",
    "for i in train_text:\n",
    "    j = str(i)\n",
    "    seq_len.append(len(j.split()))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca6acdfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Based on the histogram we are selecting the max len as 8\n",
    "pd.Series(seq_len).hist(bins = 60, range=(0,20))\n",
    "max_seq_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2de5a0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Tokenization: breaking down of the sentence into tokens\n",
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer(\n",
    "    train_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782638e4",
   "metadata": {},
   "source": [
    "<p style='font-size: 16px;'>Next, we will convert the integer sequences to tensors.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1f50381",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a242ac39",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 18px;\">Now we will create dataloaders for the training set. These dataloaders will pass batches of train data as input to the model during the training phase.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d66f5c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "#define a batch size\n",
    "batch_size = 16\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "# DataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9776ec8",
   "metadata": {},
   "source": [
    "<h1>Define Model Architecture</h1>\n",
    "\n",
    "RELU - The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0ffc98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "    \n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        self.bert=bert #model assign\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU() \n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 4)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, sent_id, mask):\n",
    "        cls_hs = self.bert(sent_id, attention_mask=mask)[0][:,0]\n",
    "        \n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d091dc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "BERT_Arch                                               --\n",
       "├─BertModel: 1-1                                        --\n",
       "│    └─BertEmbeddings: 2-1                              --\n",
       "│    │    └─Embedding: 3-1                              (23,440,896)\n",
       "│    │    └─Embedding: 3-2                              (393,216)\n",
       "│    │    └─Embedding: 3-3                              (1,536)\n",
       "│    │    └─LayerNorm: 3-4                              (1,536)\n",
       "│    │    └─Dropout: 3-5                                --\n",
       "│    └─BertEncoder: 2-2                                 --\n",
       "│    │    └─ModuleList: 3-6                             (85,054,464)\n",
       "│    └─BertPooler: 2-3                                  --\n",
       "│    │    └─Linear: 3-7                                 (590,592)\n",
       "│    │    └─Tanh: 3-8                                   --\n",
       "├─Dropout: 1-2                                          --\n",
       "├─ReLU: 1-3                                             --\n",
       "├─Linear: 1-4                                           393,728\n",
       "├─Linear: 1-5                                           131,328\n",
       "├─Linear: 1-6                                           1,028\n",
       "├─LogSoftmax: 1-7                                       --\n",
       "================================================================================\n",
       "Total params: 110,008,324\n",
       "Trainable params: 526,084\n",
       "Non-trainable params: 109,482,240\n",
       "================================================================================"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# freeze all the parameters. This will prevent updating of model weights during fine-tuning.\n",
    "\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)\n",
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e659e4",
   "metadata": {},
   "source": [
    "<h1>Optimizer</h1>\n",
    "When training a deep learning model, you must adapt every epoch's weight and minimize the loss function. An optimizer is an algorithm or function that adapts the neural network's attributes, like learning rate and weights. Hence, it assists in improving the accuracy and reduces the total loss\n",
    "\n",
    "Adam is a replacement optimization algorithm for stochastic gradient descent for training deep learning models. Adam combines the best properties of the AdaGrad and RMSProp algorithms to provide an optimization algorithm that can handle sparse gradients on noisy problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c79eeff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "# define the optimizer\n",
    "optimizer = Adam(model.parameters(), lr = 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9553d68",
   "metadata": {},
   "source": [
    "<h1>Find Class Weights</h1>\n",
    "\n",
    "Estimate class weights for unbalanced datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb62ffe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2\n",
      "1       1\n",
      "2       2\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "3995    0\n",
      "3996    3\n",
      "3997    3\n",
      "3998    3\n",
      "3999    3\n",
      "Name: label, Length: 4000, dtype: int64\n",
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "#compute the class weights\n",
    "print(train_labels)\n",
    "class_wts = compute_class_weight(class_weight='balanced', classes = np.unique(train_labels), y=train_labels)\n",
    "print(class_wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80fca52",
   "metadata": {},
   "source": [
    "<h1>Balancing the weights while calculating the error</h1>\n",
    "\n",
    "\n",
    "what is cross entropy loss\n",
    "Also called logarithmic loss, log loss or logistic loss. Each predicted class probability is compared to the actual class desired output 0 or 1 and a score/loss is calculated that penalizes the probability based on how far it is from the actual expected value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a69b01e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.], device='mps:0')\n",
      "NLLLoss()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/torch/_tensor_str.py:115: UserWarning: The operator 'aten::nonzero' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    }
   ],
   "source": [
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "print(weights)\n",
    "# loss function\n",
    "cross_entropy = nn.NLLLoss(weight=weights) \n",
    "print(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0ac7f3",
   "metadata": {},
   "source": [
    "<h1>Setting up the epochs</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50ea5f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses=[]# number of training epochs\n",
    "epochs = 20\n",
    "# We can also use learning rate scheduler to achieve better results\n",
    "lr_sch = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef472a2",
   "metadata": {},
   "source": [
    "<h1>Fine-Tune the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a518d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_preds = []\n",
    "    \n",
    "    correct = 0\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        preds = model(sent_id, mask)\n",
    "        \n",
    "        loss = cross_entropy(preds, labels)\n",
    "        total_loss = total_loss + loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        preds=preds.detach().cpu().numpy()\n",
    "        total_preds.append(preds)\n",
    "        \n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        preds = np.argmax(preds, axis = 1)\n",
    "        if (labels == preds).all():\n",
    "            correct+=1\n",
    "        \n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    print('accuracy: ', correct / len(train_dataloader), \"%\")\n",
    "    return avg_loss, total_preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31d77bb",
   "metadata": {},
   "source": [
    "<h1>Start Model Training</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ac26712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.548 %\n",
      "\n",
      "Training Loss: 0.278\n",
      "\n",
      " Epoch 2 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.616 %\n",
      "\n",
      "Training Loss: 0.232\n",
      "\n",
      " Epoch 3 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.728 %\n",
      "\n",
      "Training Loss: 0.170\n",
      "\n",
      " Epoch 4 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.7 %\n",
      "\n",
      "Training Loss: 0.117\n",
      "\n",
      " Epoch 5 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.836 %\n",
      "\n",
      "Training Loss: 0.099\n",
      "\n",
      " Epoch 6 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.676 %\n",
      "\n",
      "Training Loss: inf\n",
      "\n",
      " Epoch 7 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.788 %\n",
      "\n",
      "Training Loss: 0.113\n",
      "\n",
      " Epoch 8 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.768 %\n",
      "\n",
      "Training Loss: 0.183\n",
      "\n",
      " Epoch 9 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.732 %\n",
      "\n",
      "Training Loss: inf\n",
      "\n",
      " Epoch 10 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.804 %\n",
      "\n",
      "Training Loss: 0.103\n",
      "\n",
      " Epoch 11 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.732 %\n",
      "\n",
      "Training Loss: inf\n",
      "\n",
      " Epoch 12 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.82 %\n",
      "\n",
      "Training Loss: 0.124\n",
      "\n",
      " Epoch 13 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.796 %\n",
      "\n",
      "Training Loss: inf\n",
      "\n",
      " Epoch 14 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.768 %\n",
      "\n",
      "Training Loss: inf\n",
      "\n",
      " Epoch 15 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.764 %\n",
      "\n",
      "Training Loss: 0.080\n",
      "\n",
      " Epoch 16 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.764 %\n",
      "\n",
      "Training Loss: 0.155\n",
      "\n",
      " Epoch 17 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.836 %\n",
      "\n",
      "Training Loss: 0.124\n",
      "\n",
      " Epoch 18 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.812 %\n",
      "\n",
      "Training Loss: 0.159\n",
      "\n",
      " Epoch 19 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.8 %\n",
      "\n",
      "Training Loss: 0.147\n",
      "\n",
      " Epoch 20 / 20\n",
      "  Batch    50  of    250.\n",
      "  Batch   100  of    250.\n",
      "  Batch   150  of    250.\n",
      "  Batch   200  of    250.\n",
      "accuracy:  0.864 %\n",
      "\n",
      "Training Loss: 0.128\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)  \n",
    "    # it can make your experiment reproducible, similar to set  random seed to all options where there needs a random seed.    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9d3681",
   "metadata": {},
   "source": [
    "<h1>Get Predictions for Test Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bc3b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {1: 'order', 2: 'size',  3: 'greeting', 4: 'thank'}\n",
    "\n",
    "def get_prediction(str):\n",
    "    str = re.sub(r'[^a-zA-Z]+', '', str)\n",
    "    test_text = [str]\n",
    "    model.eval()\n",
    "    \n",
    "    tokens_test_data = tokenizer(\n",
    "        test_text,\n",
    "        max_length = 8,\n",
    "        pad_to_max_length = True,\n",
    "        truncation=True,\n",
    "        return_token_type_ids = False\n",
    "    )\n",
    "    \n",
    "    test_seq = torch.tensor(tokens_test_data['input_ids'])\n",
    "    test_mask = torch.tensor(tokens_test_data['attention_mask'])\n",
    "\n",
    "    preds = None \n",
    "    with torch.no_grad():\n",
    "        preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    \n",
    "    preds = preds.detach().cpu().numpy()\n",
    "    preds = np.argmax(preds, axis = 1)\n",
    "    return le.inverse_transform(preds)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e52dbcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium cup . - result -  2\n",
      "A mocha . - result -  1\n",
      "Have a nice day ! - result -  1\n",
      "I want a noisette , please . - result -  1\n",
      "Hi ! - result -  3\n",
      "Hey ! - result -  3\n",
      "Large . - result -  2\n",
      "Medium cup . - result -  2\n",
      "Cheers ! - result -  4\n",
      "Could I get a noisette ? - result -  1\n",
      "Have a great day ! - result -  4\n",
      "Small , thank you ! - result -  2\n",
      "Goodbye ! - result -  4\n",
      "Medium , thank you ! - result -  2\n",
      "Goodbye ! - result -  4\n",
      "Can I get a peppermint hot chocolate ? - result -  2\n",
      "A white hot chocolate , please . - result -  1\n",
      "I would like an espresso con panna . - result -  1\n",
      "I want a salted caramel hot chocolate , please . - result -  4\n",
      "Hey ! - result -  3\n",
      "A white hot chocolate , please . - result -  1\n",
      "I would like an americano , please . - result -  1\n",
      "Enjoy your day ! - result -  4\n",
      "Alright . - result -  4\n",
      "Hello ! - result -  3\n",
      "A black tea . - result -  1\n",
      "I want a flat white . - result -  4\n",
      "Hi ! - result -  3\n",
      "Small , please . - result -  2\n",
      "Have a nice day ! - result -  1\n",
      "Can I get an espresso ? - result -  1\n",
      "Could I get a cordusio ? - result -  1\n",
      "Medium cup . - result -  2\n",
      "I would like a cappuccino . - result -  1\n",
      "A flat white , please . - result -  2\n",
      "Have a nice day ! - result -  1\n",
      "Small , thank you ! - result -  2\n",
      "Medium , thank you ! - result -  2\n",
      "Medium , please . - result -  2\n",
      "Hello ! - result -  3\n",
      "Small . - result -  2\n",
      "Alright . - result -  4\n",
      "Thank you ! - result -  4\n",
      "Large , thank you ! - result -  2\n",
      "Hey ! - result -  3\n",
      "Could I have a hot chocolate , please ? - result -  1\n",
      "Could I get a salted caramel hot chocolate , please ? - result -  1\n",
      "Alright . - result -  4\n",
      "Hello ! - result -  3\n",
      "Thank you ! - result -  4\n",
      "Small , please . - result -  2\n",
      "Hey ! - result -  3\n",
      "Goodbye ! - result -  4\n",
      "Medium would do . - result -  2\n",
      "Can I get a latte , please ? - result -  2\n",
      "Could I get a salted caramel hot chocolate , please ? - result -  1\n",
      "Hey ! - result -  3\n",
      "Have a nice day ! - result -  1\n",
      "Hey ! - result -  3\n",
      "Enjoy your day ! - result -  4\n",
      "Can I have a mocha , please ? - result -  4\n",
      "Large . - result -  2\n",
      "Could I have a breakfast tea , please ? - result -  1\n",
      "May I have an espresso con panna ? - result -  2\n",
      "Large , thank you ! - result -  2\n",
      "Cheers ! - result -  4\n",
      "A flat white , please . - result -  2\n",
      "Small , thank you ! - result -  2\n",
      "Alright . - result -  4\n",
      "Hey there ! - result -  4\n",
      "I would like a green tea , please . - result -  1\n",
      "Small cup . - result -  2\n",
      "I would like a latte . - result -  1\n",
      "Enjoy your day ! - result -  4\n",
      "Hi ! - result -  3\n",
      "Large would do . - result -  2\n",
      "Have a nice day ! - result -  1\n",
      "Could I have a black tea ? - result -  1\n",
      "An iced hot chocolate . - result -  1\n",
      "Small , thank you ! - result -  2\n",
      "Medium . - result -  2\n",
      "Can I get an espresso con panna ? - result -  1\n",
      "Small cup . - result -  2\n",
      "Large , please . - result -  2\n",
      "Hey ! - result -  3\n",
      "Hey ! - result -  3\n",
      "Thanks ! - result -  4\n",
      "Hi ! - result -  3\n",
      "Large would do . - result -  2\n",
      "Thanks ! - result -  4\n",
      "Hey there ! - result -  4\n",
      "Hey ! - result -  3\n",
      "I would like an espresso , please . - result -  1\n",
      "Hello ! - result -  3\n",
      "Thanks ! - result -  4\n",
      "Hey ! - result -  3\n",
      "Goodbye ! - result -  4\n",
      "Bye ! - result -  4\n",
      "Hi ! - result -  3\n",
      "Medium cup . - result -  2\n",
      "Thank you ! - result -  4\n",
      "Can I have a latte ? - result -  1\n",
      "Hello ! - result -  3\n",
      "Hi ! - result -  3\n",
      "Hello ! - result -  3\n",
      "Alright . - result -  4\n",
      "Can I have a noisette , please ? - result -  1\n",
      "Small . - result -  2\n",
      "Large , please . - result -  2\n",
      "Hello ! - result -  3\n",
      "Medium would do . - result -  2\n",
      "Hello ! - result -  3\n",
      "Hey there ! - result -  4\n",
      "Bye ! - result -  4\n",
      "Could I have a peppermint hot chocolate , please ? - result -  2\n",
      "Hey ! - result -  3\n",
      "Medium , please . - result -  2\n",
      "Okay . - result -  4\n",
      "Hi ! - result -  3\n",
      "Bye ! - result -  4\n",
      "Can I have a hot chocolate , please ? - result -  1\n",
      "Can I get an espresso macchiato , please ? - result -  1\n",
      "Hello ! - result -  3\n",
      "Bye ! - result -  4\n",
      "Alright . - result -  4\n",
      "Small , please . - result -  2\n",
      "Small , thank you ! - result -  2\n",
      "A black tea , please . - result -  2\n",
      "Could I get a cappuccino ? - result -  1\n",
      "Medium , thank you ! - result -  2\n",
      "Enjoy your day ! - result -  4\n",
      "Medium would do . - result -  2\n",
      "Can I get an espresso ? - result -  1\n",
      "Small , thank you ! - result -  2\n",
      "Hey ! - result -  3\n",
      "Small . - result -  2\n",
      "Hey ! - result -  3\n",
      "Thanks ! - result -  4\n",
      "Have a nice day ! - result -  1\n",
      "Hello ! - result -  3\n",
      "Hey ! - result -  3\n",
      "Thank you ! - result -  4\n",
      "Can I get an iced hot chocolate , please ? - result -  1\n",
      "Thanks ! - result -  4\n",
      "An americano , please . - result -  1\n",
      "I would like a noisette , please . - result -  1\n",
      "Hello ! - result -  3\n",
      "Could I have a white hot chocolate , please ? - result -  1\n",
      "Hey there ! - result -  4\n",
      "Thank you ! - result -  4\n",
      "Medium cup . - result -  2\n",
      "Hi ! - result -  3\n",
      "Cheers ! - result -  4\n",
      "May I get a green tea ? - result -  4\n",
      "Hello ! - result -  3\n",
      "Hey ! - result -  3\n",
      "Alright . - result -  4\n",
      "Enjoy your day ! - result -  4\n",
      "Have a nice day ! - result -  1\n",
      "Goodbye ! - result -  4\n",
      "Medium . - result -  2\n",
      "Can I have a breakfast tea , please ? - result -  2\n",
      "Goodbye ! - result -  4\n",
      "Hey there ! - result -  4\n",
      "A hot chocolate , please . - result -  4\n",
      "Medium . - result -  2\n",
      "A hot chocolate , please . - result -  4\n",
      "Enjoy your day ! - result -  4\n",
      "Medium . - result -  2\n",
      "Goodbye ! - result -  4\n",
      "Hello ! - result -  3\n",
      "Can I have a salted caramel hot chocolate , please ? - result -  4\n",
      "Okay . - result -  4\n",
      "Could I have a mocha ? - result -  1\n",
      "Large , please . - result -  2\n",
      "Have a nice day ! - result -  1\n",
      "Hey there ! - result -  4\n",
      "Enjoy your day ! - result -  4\n",
      "Could I have an espresso ? - result -  1\n",
      "Thanks ! - result -  4\n",
      "Medium would do . - result -  2\n",
      "Large . - result -  2\n",
      "Cheers ! - result -  4\n",
      "Can I get a black tea , please ? - result -  1\n",
      "May I get an espresso macchiato ? - result -  2\n",
      "Hello ! - result -  3\n",
      "Can I have a peppermint hot chocolate , please ? - result -  2\n",
      "Hello ! - result -  3\n",
      "Small cup . - result -  2\n",
      "Can I get a white hot chocolate ? - result -  1\n",
      "Small cup . - result -  2\n",
      "Medium cup . - result -  2\n",
      "I want an americano . - result -  1\n",
      "Thank you ! - result -  4\n",
      "A cappuccino , please . - result -  2\n",
      "Can I have an americano , please ? - result -  1\n",
      "May I have a noisette ? - result -  4\n",
      "Could I get an Earl Grey ? - result -  1\n",
      "Small . - result -  2\n",
      "I would like a peppermint hot chocolate . - result -  2\n",
      "Could I get a white hot chocolate ? - result -  1\n",
      "Medium would do . - result -  2\n",
      "Medium . - result -  2\n",
      "Large would do . - result -  2\n",
      "Have a nice day ! - result -  1\n",
      "Small cup . - result -  2\n",
      "Large cup . - result -  2\n",
      "Can I get a breakfast tea ? - result -  1\n",
      "Bye ! - result -  4\n",
      "Small , thank you ! - result -  2\n",
      "Okay . - result -  4\n",
      "Large would do . - result -  2\n",
      "Hi ! - result -  3\n",
      "Hey there ! - result -  4\n",
      "Bye ! - result -  4\n",
      "Hello ! - result -  3\n",
      "Cheers ! - result -  4\n",
      "Could I have a cappuccino , please ? - result -  1\n",
      "I want a white hot chocolate , please . - result -  1\n",
      "Hey ! - result -  3\n",
      "Have a great day ! - result -  4\n",
      "Can I have a noisette , please ? - result -  1\n",
      "Could I get an espresso , please ? - result -  1\n",
      "Have a nice day ! - result -  1\n",
      "Medium would do . - result -  2\n",
      "Hi ! - result -  3\n",
      "Hi ! - result -  3\n",
      "Have a great day ! - result -  4\n",
      "Hey ! - result -  3\n",
      "Large . - result -  2\n",
      "Bye ! - result -  4\n",
      "Hey ! - result -  3\n",
      "Cheers ! - result -  4\n",
      "I would like an espresso macchiato , please . - result -  1\n",
      "Can I get an espresso con panna , please ? - result -  1\n",
      "Have a great day ! - result -  4\n",
      "Medium . - result -  2\n",
      "Small cup . - result -  2\n",
      "Large , please . - result -  2\n",
      "Hey ! - result -  3\n",
      "Hello ! - result -  3\n",
      "Hello ! - result -  3\n",
      "Have a nice day ! - result -  1\n",
      "Medium , please . - result -  2\n",
      "Could I get a flat white ? - result -  2\n",
      "Hey there ! - result -  4\n",
      "Large , please . - result -  2\n",
      "Enjoy your day ! - result -  4\n",
      "Can I have a white hot chocolate , please ? - result -  1\n",
      "Small , please . - result -  2\n",
      "Hey there ! - result -  4\n",
      "Have a great day ! - result -  4\n",
      "Hello ! - result -  3\n",
      "Large , thank you ! - result -  2\n",
      "Small , thank you ! - result -  2\n",
      "I would like an americano . - result -  1\n",
      "Hello ! - result -  3\n",
      "Cheers ! - result -  4\n",
      "Medium , please . - result -  2\n",
      "Can I get a cappuccino , please ? - result -  1\n",
      "Could I get a black tea ? - result -  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May I get a latte ? - result -  1\n",
      "I would like an espresso . - result -  1\n",
      "Alright . - result -  4\n",
      "Could I have a noisette , please ? - result -  1\n",
      "Hello ! - result -  3\n",
      "Goodbye ! - result -  4\n",
      "Have a great day ! - result -  4\n",
      "I want a salted caramel hot chocolate , please . - result -  4\n",
      "Large , thank you ! - result -  2\n",
      "Small would do . - result -  2\n",
      "Bye ! - result -  4\n",
      "Medium . - result -  2\n",
      "Hello ! - result -  3\n",
      "Hi ! - result -  3\n",
      "Bye ! - result -  4\n",
      "Okay . - result -  4\n",
      "Okay . - result -  4\n",
      "Hey there ! - result -  4\n",
      "Small , thank you ! - result -  2\n",
      "Medium , please . - result -  2\n",
      "Have a nice day ! - result -  1\n",
      "Could I get a peppermint hot chocolate ? - result -  1\n",
      "Hey there ! - result -  4\n",
      "Small , please . - result -  2\n",
      "Can I get a mocha ? - result -  1\n",
      "Hi ! - result -  3\n",
      "Hi ! - result -  3\n",
      "Hello ! - result -  3\n",
      "Small , please . - result -  2\n",
      "Hi ! - result -  3\n",
      "Have a nice day ! - result -  1\n",
      "Medium would do . - result -  2\n",
      "Hey there ! - result -  4\n",
      "Okay . - result -  4\n",
      "Okay . - result -  4\n",
      "Can I get a salted caramel hot chocolate ? - result -  4\n",
      "Cheers ! - result -  4\n",
      "Hello ! - result -  3\n",
      "Hey ! - result -  3\n",
      "Hi ! - result -  3\n",
      "Hello ! - result -  3\n",
      "I want a salted caramel hot chocolate . - result -  4\n",
      "Hi ! - result -  3\n",
      "Hi ! - result -  3\n",
      "Have a nice day ! - result -  1\n",
      "Enjoy your day ! - result -  4\n",
      "An espresso macchiato , please . - result -  1\n",
      "Could I get a caramel macchiato , please ? - result -  1\n",
      "I would like an espresso con panna . - result -  1\n",
      "Hello ! - result -  3\n",
      "Small would do . - result -  2\n",
      "Large . - result -  2\n",
      "Medium would do . - result -  2\n",
      "Thank you ! - result -  4\n",
      "Bye ! - result -  4\n",
      "Hey there ! - result -  4\n",
      "Can I get a cordusio ? - result -  1\n",
      "Small . - result -  2\n",
      "Medium , please . - result -  2\n",
      "Large . - result -  2\n",
      "May I have a cordusio ? - result -  2\n",
      "Small , please . - result -  2\n",
      "Small . - result -  2\n",
      "Large cup . - result -  2\n",
      "Hey there ! - result -  4\n",
      "May I have a mocha ? - result -  1\n",
      "Hello ! - result -  3\n",
      "Okay . - result -  4\n",
      "Hello ! - result -  3\n",
      "Medium cup . - result -  2\n",
      "May I have a noisette ? - result -  4\n",
      "I want a hot chocolate . - result -  1\n",
      "Large would do . - result -  2\n",
      "Alright . - result -  4\n",
      "Small would do . - result -  2\n",
      "Hey ! - result -  3\n",
      "Can I get a cordusio , please ? - result -  1\n",
      "Could I have a green tea ? - result -  1\n",
      "Hi ! - result -  3\n",
      "Hello ! - result -  3\n",
      "Enjoy your day ! - result -  4\n",
      "Can I get a cordusio , please ? - result -  1\n",
      "Goodbye ! - result -  4\n",
      "Have a great day ! - result -  4\n",
      "Enjoy your day ! - result -  4\n",
      "Enjoy your day ! - result -  4\n",
      "Medium . - result -  2\n",
      "Can I have an espresso con panna , please ? - result -  2\n",
      "Large would do . - result -  2\n",
      "Hey ! - result -  3\n",
      "Goodbye ! - result -  4\n",
      "Have a nice day ! - result -  1\n",
      "Hi ! - result -  3\n",
      "Large , thank you ! - result -  2\n",
      "Could I have a white hot chocolate ? - result -  1\n",
      "Hey there ! - result -  4\n",
      "Hey there ! - result -  4\n",
      "Goodbye ! - result -  4\n",
      "Goodbye ! - result -  4\n",
      "Could I have an espresso macchiato ? - result -  1\n",
      "Small would do . - result -  2\n",
      "Enjoy your day ! - result -  4\n",
      "Small , please . - result -  2\n",
      "Bye ! - result -  4\n",
      "Can I get a mocha ? - result -  1\n",
      "Small cup . - result -  2\n",
      "Small . - result -  2\n",
      "Medium , thank you ! - result -  2\n",
      "Hey ! - result -  3\n",
      "Hey there ! - result -  4\n",
      "May I have a peppermint hot chocolate ? - result -  2\n",
      "Medium , thank you ! - result -  2\n",
      "Hey ! - result -  3\n",
      "Hey there ! - result -  4\n",
      "Cheers ! - result -  4\n",
      "Alright . - result -  4\n",
      "Can I get a latte ? - result -  1\n",
      "Hey ! - result -  3\n",
      "Hello ! - result -  3\n",
      "Can I have a mocha ? - result -  1\n",
      "Large . - result -  2\n",
      "Hey there ! - result -  4\n",
      "Hey there ! - result -  4\n",
      "Hello ! - result -  3\n",
      "Can I have an americano , please ? - result -  1\n",
      "Hey there ! - result -  4\n",
      "Hey there ! - result -  4\n",
      "Can I get a noisette , please ? - result -  1\n",
      "Hello ! - result -  3\n",
      "Thanks ! - result -  4\n",
      "Small . - result -  2\n",
      "Have a great day ! - result -  4\n",
      "Large . - result -  2\n",
      "Small cup . - result -  2\n",
      "Hello ! - result -  3\n",
      "Medium , thank you ! - result -  2\n",
      "Medium would do . - result -  2\n",
      "I want a mocha , please . - result -  1\n",
      "Small . - result -  2\n",
      "accuracy:  83.75 %\n"
     ]
    }
   ],
   "source": [
    "labels = {1: 'order', 2: 'size',  3: 'greeting', 4: 'thank'}\n",
    "correct =0\n",
    "\n",
    "for i in range(len(test_text)):\n",
    "    result = get_prediction(test_text[i])\n",
    "    print(test_text[i], '- result - ', result)\n",
    "    if result == test_labels[i]:\n",
    "        correct +=1\n",
    "        \n",
    "print(\"accuracy: \", (correct / len(test_text))*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d579f3e0",
   "metadata": {},
   "source": [
    "<h1>Let's test the model now:</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b788b97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order\n"
     ]
    }
   ],
   "source": [
    "s = \"Can i get black tea\"\n",
    "result = get_prediction(s)\n",
    "print(labels[result])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55a481",
   "metadata": {},
   "source": [
    "<h1>Save model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a0d8594",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='/Users/aon97/programming/chatbot/model/chatbotmodel1.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "021d4dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f206b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='/Users/aon97/programming/chatbot/model/chatbotmodel.pth'\n",
    "model = BERT_Arch(bert)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a237a4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
